{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fafb4342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "NON-IDEMPOTENT LOAD: sales_2024_06_01.csv\n",
      "==================================================\n",
      "Daily rows to load: 3\n",
      "Warehouse rows BEFORE: 0\n",
      "Warehouse rows AFTER: 3\n",
      "\n",
      "Warehouse after first run:\n",
      "  order_id  order_date customer   product  amount\n",
      "0     S001  2024-06-01    Alice  Widget A    75.0\n",
      "1     S002  2024-06-01      Bob  Widget B    50.0\n",
      "2     S003  2024-06-01  Charlie  Widget A   150.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Savithadevi\\AppData\\Local\\Temp\\ipykernel_48504\\1002458935.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  warehouse_df = pd.concat([warehouse_df, daily_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Build Non-Idempotent Loader (The Problem)\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_non_idempotent(daily_file, warehouse_file):\n",
    "    \"\"\"\n",
    "    NON-IDEMPOTENT loader: blindly appends daily data to warehouse.\n",
    "    Running this twice = DUPLICATE DATA.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"NON-IDEMPOTENT LOAD: {daily_file}\")\n",
    "    print(f\"{'=' * 50}\")\n",
    "    \n",
    "    # Read daily extract\n",
    "    daily_df = pd.read_csv(daily_file)\n",
    "    print(f\"Daily rows to load: {len(daily_df)}\")\n",
    "    \n",
    "    # Read current warehouse\n",
    "    if os.path.exists(warehouse_file) and os.path.getsize(warehouse_file) > 0:\n",
    "        warehouse_df = pd.read_csv(warehouse_file)\n",
    "    else:\n",
    "        warehouse_df = pd.DataFrame(columns=daily_df.columns)\n",
    "    \n",
    "    print(f\"Warehouse rows BEFORE: {len(warehouse_df)}\")\n",
    "    \n",
    "    # BLIND APPEND — the problem!\n",
    "    warehouse_df = pd.concat([warehouse_df, daily_df], ignore_index=True)\n",
    "    \n",
    "    # Save back\n",
    "    warehouse_df.to_csv(warehouse_file, index=False)\n",
    "    print(f\"Warehouse rows AFTER: {len(warehouse_df)}\")\n",
    "    \n",
    "    return warehouse_df\n",
    "\n",
    "    # Reset warehouse\n",
    "pd.DataFrame(columns=[\"order_id\",\"order_date\",\"customer\",\"product\",\"amount\"]).to_csv(\"warehouse.csv\", index=False)\n",
    "\n",
    "# First run\n",
    "result = load_non_idempotent(\"sales_2024_06_01.csv\", \"warehouse.csv\")\n",
    "print(f\"\\nWarehouse after first run:\")\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08d97501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "NON-IDEMPOTENT LOAD: sales_2024_06_01.csv\n",
      "==================================================\n",
      "Daily rows to load: 3\n",
      "Warehouse rows BEFORE: 3\n",
      "Warehouse rows AFTER: 6\n",
      "\n",
      "Warehouse after SECOND run (re-run):\n",
      "  order_id  order_date customer   product  amount\n",
      "0     S001  2024-06-01    Alice  Widget A    75.0\n",
      "1     S002  2024-06-01      Bob  Widget B    50.0\n",
      "2     S003  2024-06-01  Charlie  Widget A   150.0\n",
      "3     S001  2024-06-01    Alice  Widget A    75.0\n",
      "4     S002  2024-06-01      Bob  Widget B    50.0\n",
      "5     S003  2024-06-01  Charlie  Widget A   150.0\n",
      "\n",
      "⚠️  PROBLEM: 6 rows — we have DUPLICATES!\n"
     ]
    }
   ],
   "source": [
    "# Second run — same file, same day\n",
    "result = load_non_idempotent(\"sales_2024_06_01.csv\", \"warehouse.csv\")\n",
    "print(f\"\\nWarehouse after SECOND run (re-run):\")\n",
    "print(result)\n",
    "print(f\"\\n⚠️  PROBLEM: {len(result)} rows — we have DUPLICATES!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c884911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Idempotent Loader (The Fix)\n",
    "\n",
    "def load_idempotent(daily_file, warehouse_file):\n",
    "    \"\"\"\n",
    "    IDEMPOTENT loader: delete existing data for the partition, then insert.\n",
    "    Running this 1 time or 100 times produces the SAME result.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"IDEMPOTENT LOAD: {daily_file}\")\n",
    "    print(f\"{'=' * 50}\")\n",
    "    \n",
    "    # Read daily extract\n",
    "    daily_df = pd.read_csv(daily_file)\n",
    "    partition_date = daily_df[\"order_date\"].iloc[0]\n",
    "    print(f\"Daily rows to load: {len(daily_df)}\")\n",
    "    print(f\"Partition date: {partition_date}\")\n",
    "    \n",
    "    # Read current warehouse\n",
    "    if os.path.exists(warehouse_file) and os.path.getsize(warehouse_file) > 0:\n",
    "        warehouse_df = pd.read_csv(warehouse_file)\n",
    "    else:\n",
    "        warehouse_df = pd.DataFrame(columns=daily_df.columns)\n",
    "    \n",
    "    print(f\"Warehouse rows BEFORE: {len(warehouse_df)}\")\n",
    "    \n",
    "    # STEP 1: DELETE existing rows for this partition date\n",
    "    rows_before_delete = len(warehouse_df)\n",
    "    warehouse_df = warehouse_df[warehouse_df[\"order_date\"] != partition_date]\n",
    "    rows_deleted = rows_before_delete - len(warehouse_df)\n",
    "    print(f\"Rows deleted for partition {partition_date}: {rows_deleted}\")\n",
    "    \n",
    "    # STEP 2: INSERT fresh data\n",
    "    warehouse_df = pd.concat([warehouse_df, daily_df], ignore_index=True)\n",
    "    print(f\"Rows inserted: {len(daily_df)}\")\n",
    "    \n",
    "    # Save back\n",
    "    warehouse_df.to_csv(warehouse_file, index=False)\n",
    "    print(f\"Warehouse rows AFTER: {len(warehouse_df)}\")\n",
    "    \n",
    "    return warehouse_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "733f73d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== RUN 1 =====\n",
      "\n",
      "==================================================\n",
      "IDEMPOTENT LOAD: sales_2024_06_01.csv\n",
      "==================================================\n",
      "Daily rows to load: 3\n",
      "Partition date: 2024-06-01\n",
      "Warehouse rows BEFORE: 0\n",
      "Rows deleted for partition 2024-06-01: 0\n",
      "Rows inserted: 3\n",
      "Warehouse rows AFTER: 3\n",
      "\n",
      "===== RUN 2 (re-run) =====\n",
      "\n",
      "==================================================\n",
      "IDEMPOTENT LOAD: sales_2024_06_01.csv\n",
      "==================================================\n",
      "Daily rows to load: 3\n",
      "Partition date: 2024-06-01\n",
      "Warehouse rows BEFORE: 3\n",
      "Rows deleted for partition 2024-06-01: 3\n",
      "Rows inserted: 3\n",
      "Warehouse rows AFTER: 3\n",
      "\n",
      "===== RUN 3 (another re-run) =====\n",
      "\n",
      "==================================================\n",
      "IDEMPOTENT LOAD: sales_2024_06_01.csv\n",
      "==================================================\n",
      "Daily rows to load: 3\n",
      "Partition date: 2024-06-01\n",
      "Warehouse rows BEFORE: 3\n",
      "Rows deleted for partition 2024-06-01: 3\n",
      "Rows inserted: 3\n",
      "Warehouse rows AFTER: 3\n",
      "\n",
      "===== IDEMPOTENCY VERIFICATION =====\n",
      "Rows after run 1: 3\n",
      "Rows after run 2: 3\n",
      "Rows after run 3: 3\n",
      "All results identical: True\n",
      "✅ IDEMPOTENT: Safe to re-run!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Savithadevi\\AppData\\Local\\Temp\\ipykernel_48504\\3268920473.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  warehouse_df = pd.concat([warehouse_df, daily_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Reset warehouse\n",
    "pd.DataFrame(columns=[\"order_id\",\"order_date\",\"customer\",\"product\",\"amount\"]).to_csv(\"warehouse.csv\", index=False)\n",
    "\n",
    "print(\"===== RUN 1 =====\")\n",
    "result1 = load_idempotent(\"sales_2024_06_01.csv\", \"warehouse.csv\")\n",
    "\n",
    "print(\"\\n===== RUN 2 (re-run) =====\")\n",
    "result2 = load_idempotent(\"sales_2024_06_01.csv\", \"warehouse.csv\")\n",
    "\n",
    "print(\"\\n===== RUN 3 (another re-run) =====\")\n",
    "result3 = load_idempotent(\"sales_2024_06_01.csv\", \"warehouse.csv\")\n",
    "\n",
    "print(\"\\n===== IDEMPOTENCY VERIFICATION =====\")\n",
    "print(f\"Rows after run 1: {len(result1)}\")\n",
    "print(f\"Rows after run 2: {len(result2)}\")\n",
    "print(f\"Rows after run 3: {len(result3)}\")\n",
    "\n",
    "are_equal = result1.equals(result2) and result2.equals(result3)\n",
    "print(f\"All results identical: {are_equal}\")\n",
    "\n",
    "if are_equal:\n",
    "    print(\"✅ IDEMPOTENT: Safe to re-run!\")\n",
    "else:\n",
    "    print(\"❌ NOT IDEMPOTENT: Results differ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "527c3bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== LOADING JUNE 1 =====\n",
      "\n",
      "==================================================\n",
      "IDEMPOTENT LOAD: sales_2024_06_01.csv\n",
      "==================================================\n",
      "Daily rows to load: 3\n",
      "Partition date: 2024-06-01\n",
      "Warehouse rows BEFORE: 0\n",
      "Rows deleted for partition 2024-06-01: 0\n",
      "Rows inserted: 3\n",
      "Warehouse rows AFTER: 3\n",
      "\n",
      "===== LOADING JUNE 2 =====\n",
      "\n",
      "==================================================\n",
      "IDEMPOTENT LOAD: sales_2024_06_02.csv\n",
      "==================================================\n",
      "Daily rows to load: 2\n",
      "Partition date: 2024-06-02\n",
      "Warehouse rows BEFORE: 3\n",
      "Rows deleted for partition 2024-06-02: 0\n",
      "Rows inserted: 2\n",
      "Warehouse rows AFTER: 5\n",
      "\n",
      "===== FINAL WAREHOUSE =====\n",
      "  order_id  order_date customer   product  amount\n",
      "0     S001  2024-06-01    Alice  Widget A    75.0\n",
      "1     S002  2024-06-01      Bob  Widget B    50.0\n",
      "2     S003  2024-06-01  Charlie  Widget A   150.0\n",
      "3     S004  2024-06-02    Diana  Widget C    30.0\n",
      "4     S005  2024-06-02    Alice  Widget B   100.0\n",
      "\n",
      "Total rows: 5\n",
      "Unique dates: ['2024-06-01', '2024-06-02']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Savithadevi\\AppData\\Local\\Temp\\ipykernel_48504\\3268920473.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  warehouse_df = pd.concat([warehouse_df, daily_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Reset warehouse\n",
    "pd.DataFrame(columns=[\"order_id\",\"order_date\",\"customer\",\"product\",\"amount\"]).to_csv(\"warehouse.csv\", index=False)\n",
    "\n",
    "print(\"===== LOADING JUNE 1 =====\")\n",
    "load_idempotent(\"sales_2024_06_01.csv\", \"warehouse.csv\")\n",
    "\n",
    "print(\"\\n===== LOADING JUNE 2 =====\")\n",
    "load_idempotent(\"sales_2024_06_02.csv\", \"warehouse.csv\")\n",
    "\n",
    "print(\"\\n===== FINAL WAREHOUSE =====\")\n",
    "final = pd.read_csv(\"warehouse.csv\")\n",
    "print(final)\n",
    "print(f\"\\nTotal rows: {len(final)}\")\n",
    "print(f\"Unique dates: {sorted(final['order_date'].unique())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9eeed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RE-RUN JUNE 1 =====\n",
      "\n",
      "==================================================\n",
      "IDEMPOTENT LOAD: sales_2024_06_01.csv\n",
      "==================================================\n",
      "Daily rows to load: 3\n",
      "Partition date: 2024-06-01\n",
      "Warehouse rows BEFORE: 5\n",
      "Rows deleted for partition 2024-06-01: 3\n",
      "Rows inserted: 3\n",
      "Warehouse rows AFTER: 5\n",
      "\n",
      "Total rows: 5\n",
      "June 1 rows: 3\n",
      "June 2 rows: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== RE-RUN JUNE 1 =====\")\n",
    "load_idempotent(\"sales_2024_06_01.csv\", \"warehouse.csv\")\n",
    "\n",
    "final = pd.read_csv(\"warehouse.csv\")\n",
    "print(f\"\\nTotal rows: {len(final)}\")\n",
    "print(f\"June 1 rows: {len(final[final['order_date'] == '2024-06-01'])}\")\n",
    "print(f\"June 2 rows: {len(final[final['order_date'] == '2024-06-02'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882f319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29efbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
